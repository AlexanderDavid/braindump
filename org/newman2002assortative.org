#+setupfile:./hugo_setup.org
#+TITLE: Assortative mixing in networks
#+ROAM_KEY: cite:newman2002assortative
#+ROAM_TAGS: Paper "Network Science"

- tags :: [[file:20200825162306-network_science.org][Network Science]]

* Notes
:PROPERTIES:
:Custom_ID: newman2002assortative
:NOTER_DOCUMENT: /home/alex/Dropbox/notes/papers/newman2002assortative.pdf
:AUTHOR: Newman, M. E.
:JOURNAL: 
:DATE: 
:YEAR: 2002
:DOI: 
:URL: 
:END:
- $p_k$ - Probability that a randomly chosen vertex in the graph has the degree $k$
- Some vertex $v$ reached by randomly following some edge $e$ has a degree $k$ with a probability proportional to $k p_k$ because it is related to both the degree of the node (as nodes with higher degrees will be linked to more) as well as the underlying $k$ distribution.
- The remaining degree distribution of a node is the probability distribution of the number of edges leaving the vertex other than the one we arrived on. Because this is one less than the total degree it is proportional to $(k + 1)p_{k+1}$ where $k$ is the remaining degree but $p$ is still the same as above.
  + This is called $q_{k}$ and is normalized to be:
            \begin{eqnarray}
            \label{eq:1}
            q_{k} = \frac{(k+1)p_{k+1}}{\Sigma_{j}j p_{j}}
            \end{eqnarray}
- $e_{jk}$ is the joint probability distribution that the degrees of two nodes at either end of a random edge are $j$ and $k$ respectively
  + $e_{jk} = e_{kj}$
  + $\Sigma_{jk}e_{jk}=1$
  + $\Sigma_{j}e_{jk} = q_{k}$
- The less assortative mixing a network has the closer $e_{jk}$ is to $q_{j}q_{k}$
  + If the network is assortative we can quantify that by the connected degree-degree correlation function:
    - $\langle jk \rangle - \langle j \rangle \langle k \rangle = \Sigma_{jk} jk(e_{jk}-q_{j}q_{k})$
    - Where $\langle \dots \rangle$ indicates an average over all edges
    - This is 0 for no assortative mixing and positive for assortative mixing and negative for disasortative mixing
    - This is normalized:
      + $e_{jk}$ for a perfectly assortative network is $q_{k}\delta_{jk}$ where nodes only connect to other nodes if they are the same degree ($\delta$ is the Kronecker delta).
      + This normalization value is equal to the variance of $q_{k}$:
        - $\sigma_{q}^{2}=\Sigma_{k}k^{2}q_{k}-[\Sigma_{k}kq_{k}]^{2}$
      + And so the normalized correlation function is:
        - $r = \frac{1}{\sigma_{q}^{2}}\Sigma_{jk} jk(e_{jk}-q_{j}q_{k})$
        - This is equal to the Pearson correlation coefficient of the degrees at either ends of an edge and can be written as the following:
          - $r=\frac{M^{-1} \sum_{i} j_{i} k_{i}-\left[M^{-1} \sum_{i} \frac{1}{2}\left(j_{i}+k_{i}\right)\right]^{2}}{M^{-1} \sum_{i} \frac{1}{2}\left(j_{i}^{2}+k_{i}^{2}\right)-\left[M^{-1} \sum_{i} \frac{1}{2}\left(j_{i}+k_{i}\right)\right]^{2}}$
          - Where $j_{i}, k_{i}$ are the degrees of the verteces ot the ends of the $i\text{-th}$ edge with $i = 1\dots M$
- Proposition of a theoretical model for exactly solving many properties for an assortatively mixed network
  + Consider the ensemble of graphs in which $e_{jk}$ takes some value
  + This defines a random graph model similar to other random graphs with some specified degree sequence except this model relates to assortative mixing
  + Consider some random graph with many edges and a random edge in that graph attached to some vertex with degree $j$
  + The probability distribution of the number of other vertecies reachable from that vertex is defined as a result of the generator function $G_{j}(x)$
  + $G_{j}(x)$ must satisfy self-consistency condtion of the following form:
\begin{eqnarray}
\label{eq:2}
G_{j}(x)=x\frac{\Sigma_{k}e_{jk}[G_{k}(x)]^{k}}{\Sigma_{k}e_{jk}}
\end{eqnarray}

  + The number of vertexes reachable from some randomly chosen vertex is generated by
\begin{eqnarray}
\label{eq:3}
H(x) = x p_{0} + x \Sigma ^{\infty}_{k=1}p_{k}[G_{k-1}(x)]^{k}
\end{eqnarray}
  + The average size of the component to this vertex belongs to is the derivative of $H$
    - $\langle s \rangle = H'(1) = 1 + \Sigma_{k}k p_{k} G'_{k-1}(1)$
    - Further differentiation of $G$ gives us:
      + $\langle s \rangle = 1 - z \mathbf{q} \cdot \mathbf{A}^{-1} \cdot \mathbf{q}$
        - Where $z$ is the mean degree, $\mathbf{q}$ is the vector whos elements are $q_{k}$ and $\mathbf{A}$ is the asymmetric matrix with elements $A_{ij}=ke_{jk}-q_{k}\delta_{jk}$
        - This equation diverges at the point where $det(A) = 0$ and this point is the transition at which the graph is formed by a giant component.
        - A giant component exists when $det(A) > 0$ or when $\langle s \rangle$ is large
    - To calculate the size $S$ of the giant component:
      + Define $u_{k}$ to be the prob that an ednge connected to a vertex of remaining degree $k$ leads to another vertex that does not belong to the giant component then:
        - $S = 1 - p_{0} - \Sigma^{\infty}_{k=1}p_{k}u^{k}_{k-1}$
        - $u_{j} = \frac{\Sigma_{k}e_{jk}u_{k}^{k}}{\Sigma_{k}e_{jk}}$
        - Not usually possible to solve for $S$ in this closed form however we can approximate it using numerical iteration for some set of starting value for $u_{k}$


* Summary
In this paper Newman proposes a measure, model, and experimental results for assortative mixing within a network. A network is assortatively mixed if nodes of similar degrees connect to each other frequently, and is dissassortatively mixed if nodes of dissimilar degrees tend to connect to each other frequently. He begins by laying the theoretical groundwork to propose a numerical measure for a networks assortative mixing. The foundation for this measure is the degree distribution $p_k$, this is defined as the probability some random chosen vertex within the graph has degree $k$. This is then extended to the remaining degree distribution $q_k$ which is defined as the probability that the vertex found by following some random edge has $k$ other edges, excluding the edge followed to find the vertex. This value is then normalized by taking it as a fraction of the sum of the degree distributions as shown in Equation [[eq:1]].

#+NAME: eq:1
\begin{eqnarray}
\label{eq:1}
q_{k} = \frac{(k+1)p_{k+1}}{\Sigma_{j}j p_{j}}
\end{eqnarray}

Newman moves on to propose a numerical measure of network assortativity. This begins with defining $e_{jk}$ as the joint probability distribution that the degrees of the vertexes at either end of some random edge are $j$ and $k$ respectively. Newman then states that a network exhibiting less assortative mixing also has the value of $e_{jk}$ closer to $q_{j}q_{k}$. A networks assortativeness can then be quantified by the sum of these differences weighted by the product of the weights $\Sigma_{jk} jk(e_{jk}-q_{j}q_{k})$. This value is 0 for no assortative or disassortative mixing, positive for assortative mixing, and negative for disassortative mixing.
This measure can be normalized by taking it as a fraction of this value for a perfectly assortative network. The $e_{jk}$ for a network like this is $q_{k}\delta_{jk}$ where $\delta$ is the Kronecker delta. This normalization value is equal to the varience of $q_{k}$ or $\sigma_{q}^{2}=\Sigma_{k}k^{2}q_{k}-[\Sigma_{k}kq_{k}]^{2}$. This normalized value of assortativeness can now be expressed as $\frac{1}{\sigma_{q}^{2}}\Sigma_{jk} jk(e_{jk}-q_{j}q_{k})$ which is equal to the Pearson correlation coefficient of the degrees at either end of an edge and can be written as shown in Equation [[eq:2]]
#+NAME: eq:2
\begin{eqnarray}
\label{eq:2}
    r=\frac{M^{-1} \sum_{i} j_{i} k_{i}-\left[M^{-1} \sum_{i} \frac{1}{2}\left(j_{i}+k_{i}\right)\right]^{2}}{M^{-1} \sum_{i} \frac{1}{2}\left(j_{i}^{2}+k_{i}^{2}\right)-\left[M^{-1} \sum_{i} \frac{1}{2}\left(j_{i}+k_{i}\right)\right]^{2}}
\end{eqnarray}
where $j_{i}\text{, }k_{i}$ are the degrees at the vertexes at either end of the $i\text{-th}$ edge with $i=1\dotsM$.

Finally Newman proposes and analyzes a theoretical model that takes into account the assortativeness of a network as its parameter. Using this model he derives closed forms for the presence and size of a giant component within the graph. This model is defined based on the some given joint probability distribution $e_{jk}$. Consider a random graph that is both large and within the set of models with this joint probability distribution. $G_{j}(x)$ is defined as the generator function that returns the probability distribution of the number of vertexes reachable from some vertex $j$. This $G_{j}(x)$ must satisfy the self-consistency condition as shown in Equation [[eq:3]].

#+NAME: eq:3
\begin{eqnarray}
\label{eq:3}
G_{j}(x)=x\frac{\Sigma_{k}e_{jk}[G_{k}(x)]^{k}}{\Sigma_{k}e_{jk}}
\end{eqnarray}

The number of vertexes reachable from some randomly chosen vertex is then generated by $H$ as shown in [[eqn:4]]

#+NAME: eqn:4
\begin{eqnarray}
\label{eq:4}
H(x) = x p_{0} + x \Sigma ^{\infty}_{k=1}p_{k}[G_{k-1}(x)]^{k}
\end{eqnarray}

We can find the average size of the component that the vertex belongs to by taking the derivative of $H$ and so $\langle s \rangle = H'(1) = 1 + \Sigma_{k}kp_{k}G'_{k-1}(1)$ where $\langle s \rangle$ is the average size of the component. Further differentiation of $G$ gives us  $\langle s \rangle = 1 - z \mathbf{q} \cdot \mathbf{A}^{-1} \cdot \mathbf{q}$. Where $z$ is the mean degree, $\mathbf{q}$ is the vector whose elements are $q_{k}$ and $\mathbf{A}$ is the asymmetric matrix with elements $A_{ij}=ke_{jk}-q_{k}\delta_{jk}$. This equation diverges when $det(A) = 0$ and this point is the transition at which the graph is formed by a giant component. This giant component exists when $det(A) > 0$ or when $\langle s \rangle$ is large.
To calculate the size $S$ of the giant component we first define $u_{k}$ to be the probability that an edge connected to a vertex of remaining degree $k$ leads to another vertex that does not belong in the giant component as shown in Equation [[eqn:4]]. Then $S$ can be written in terms of $u_{k - 1}$ rather than $G_{k-1}$ as shown in Equation [[eqn:5]].

#+NAME:eqn:4
\begin{eqnarray}
\label{eq:4}
u_{j} = \frac{\Sigma_{k}e_{jk}u_{k}^{k}}{\Sigma_{k}e_{jk}}
\end{eqnarray}
#+NAME:eqn:5
\begin{eqnarray}
\label{eq:5}
S = 1 - p_{0} - \Sigma^{\infty}_{k=1}p_{k}u^{k}_{k-1}
\end{eqnarray}

In the final section of the paper details some results of the analysis. The main result is that networks with high assortativity, such as social networks, are very resiliant to vertex removal, and that networks with high disassortativity, such as devices on the internet, are not resiliant to vertex removal. This is an especially grim realization in the context of today is it means social networks as they relate to disease transmission are hard to disrupt and technological networks are easy to disrupt.

* Issues
** Overall Paper Formatting
While the formatting of a paper does not directly correlate to the importance of the information within it, it is still important to clearly separate the boundaries between ideas within the work. Newman neglects to use any section headers and so it makes it harder to distinguish when a new idea is presented or even when the novel ideas begin and the background work ends. Newman also relies heavily on derivations from other references in this work. This means that a reader has to dig through multiple other papers in order to determine the mathamatical background to this work.
** Assortativeness is not the whole picture
In the second paragraph of this paper Newman proposes that there is an important element missing from all of the current models for analyzing generic networks. However, Newman's model of networks is based purely on assortativeness. This leaves no room to tweek other parameters of the network explicitly and one has to rely on the theory of large numbers, if anything, in order to assume that the analysis on the generic model can be applied to a more specific network. This issue could be fixed by adding more parameters to the network model. While this may lead to more complex derevations it will ultimately lead to a more complete model of networks in a specific domain.
** Assortativeness is calculated purely on node degree
A network can be assortative with respect to any number of things. While the assortativeness of a network with respect to the degrees of its vertexes can be useful in some analysis it is also useless in others. It would be useful to make this model more generic and allow analysis on a network that models assortativeness as it relates to some specific class that each node is in. However, as with most things, this may make the derevations more complex and lead to the need for a more in depth overall analysis of the network.
** Assortativeness of components
It could be useful to try to find some components within a network that exibit large assortative properties. This way you might be able to find small tightly knit social groups within a larger, more complex social network. The overall assortative quantity for the graph could be 0 only because there are two giant components, one highly disassortative and the other highly assortative. However, finding these components may be exceptionally computationally expensive and might be outside the scope of this paper.

* Modularity Calculation
[[file:./images/2020-10-05_19-06-17_screenshot.png]]
The modularity, $Q$, of a network is defined as $\frac{q}{m}$ where $q$ is the total number of edges between similar vertices and $m$ is the expected number of edges between similar vertices in a random model. The derivations for $Q$ and $q$ are shown below. *Note:* rather than the actual values of similar and expected edges the ratio is used, however the end result will still be similar because these values are tightly correlated.

#+NAME: eqn:6
\begin{eqnarray}
\label{eq:6}
q & = &\frac{1}{2} \Sigma_{ij}A_{ij}\delta(c_{i}, c_{j}) - \frac{1}{2}\Sigma{ij}\frac{d(i)d(j)}{2m}\delta(c_{i},c_{j})\\
  & = &\frac{1}{2} [0.258 + 0.157 + 0.306 + 0.016] - \frac{1}{2}\Sigma{ij}\frac{d(i)d(j)}{2m}\delta(c_{i},c_{j})\\
  & = &\frac{1}{2} 0.737 - \frac{1}{2}\Sigma{ij}\frac{d(i)d(j)}{2m}\delta(c_{i},c_{j})\\
  & = &0.3685 - \frac{1}{2}\Sigma{ij}\frac{d(i)d(j)}{2m}\delta(c_{i},c_{j})\\
  & = &0.3685 - \frac{1}{2}[\frac{0.323 \cdot 0.289}{2} + \frac{0.204 \cdot 0.247}{2} + \frac{0.423 \cdot 0.377}{2} + \frac{0.084 \cdot 0.053}{2}]\\
  & = &0.3685 - \frac{1}{2}[0.0466735 + 0.025194 + 0.0797355 + 0.002226]\\
  & = &0.3685 - \frac{1}{2}[0.153829]\\
  & = &0.3685 - 0.0769145\\
  & = &0.2915855
\end{eqnarray}

#+NAME: eqn:7
\begin{eqnarray}
\label{eq:7}
Q & = & \frac{q}{m} \\
  & = & \frac{0.2915855}{1}\\
  & = & 0.2915855
\end{eqnarray}
